{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reaction:\n",
    "\n",
    "$m \\to m + G, \\text{rate}: k_{TL} * [m]$\n",
    "\n",
    "$G \\to 0    , \\text{rate}: \\xi$\n",
    "\n",
    "$m \\to 0    , \\text{rate}: \\delta$\n",
    " \n",
    "## State of the system:\n",
    "$X = [X_1, X_2]$ with\n",
    "\n",
    "$X_1 = [G]$: eGFP concentration\n",
    "\n",
    "$X_2 = [m]$: mRNA concentration\n",
    "\n",
    "## Dynamics:\n",
    "\n",
    "$\\frac{d}{dt}X_2 = -\\delta \\cdot X_2$\n",
    "\n",
    "$\\frac{d}{dt}X_1 = k_{TL} \\cdot X_2 - \\xi \\cdot X_1$\n",
    "\n",
    "## Measurement:\n",
    "$Y = X_2$\n",
    "\n",
    "## Observables of the system:\n",
    "$y(t) = h(\\theta, x(t))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pypesto\n",
    "import pypesto.petab\n",
    "import pypesto.sample as sample\n",
    "import pypesto.visualize as visualize\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import gammaln\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Load experimental data\n",
    "df=pd.read_csv('mRNA-transfection/data.csv', sep='\\t')\n",
    "\n",
    "add_offset_to_data = True\n",
    "offset_value = 0.2\n",
    "\n",
    "if add_offset_to_data:\n",
    "    df.Measurement=df.Measurement+offset_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def analytical_x2(t, t0, kTL_m0, xi, delta):\n",
    "    X = [np.exp(-delta*(t-t0)) * (t>t0),\n",
    "         kTL_m0 * (np.exp(-xi*(t-t0)) - np.exp(-delta*(t-t0))) / (delta-xi) * (t>t0)]\n",
    "    return X[1]\n",
    "\n",
    "def simulate_model(x, tvec):\n",
    "    # assign parameters\n",
    "    t0, kTL_m0, xi, delta, offset, _ = x\n",
    "    # simulate model\n",
    "    simulation = np.asarray([analytical_x2(t, t0, kTL_m0, xi, delta)\n",
    "                             for t in tvec])\n",
    "    return offset+simulation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the model, we need to define the objective function. This time we will do it via an external function that will be used then by pyPESTO instead of using the built-in ones.\n",
    "\n",
    "For numerical reasons we will implement the log likelihood and log prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def log_prior(x):\n",
    "    \"\"\" Log prior function.\"\"\"\n",
    "    # assign variables from input x\n",
    "    offset = x[-2]\n",
    "    precision = x[-1]\n",
    "    \n",
    "    # evaluate log normal-gamma prior\n",
    "    l_prior = alpha * np.log(beta) + (alpha - 0.5) * np.log(precision) \\\n",
    "            + 0.5 * (np.log(kappa) - np.log(2) - np.log(np.pi)) - gammaln(alpha) \\\n",
    "            - beta*precision - 0.5*precision*kappa*(offset - mu)**2\n",
    "    \n",
    "    return l_prior\n",
    "\n",
    "\n",
    "def negative_log_posterior(x):\n",
    "    \"\"\" Negative log posterior function.\"\"\"\n",
    "\n",
    "    precision = x[-1]                                                                            \n",
    "                                                                                \n",
    "    # experimental data\n",
    "    data = np.asarray(df.Measurement)\n",
    "    # time vector\n",
    "    tvec = np.asarray(df.Time)\n",
    "    \n",
    "    n_timepoints = len(tvec)\n",
    "    \n",
    "    # transform parameter scale\n",
    "    _x = deepcopy(x)\n",
    "    _x[:-2] = np.power(10, _x[:-2])\n",
    "    \n",
    "    # simulate model\n",
    "    simulation = simulate_model(_x, tvec)\n",
    "    \n",
    "    # evaluate standard log likelihood\n",
    "    res = data - simulation\n",
    "    sum_res = np.sum(res**2)\n",
    "    \n",
    "    constant = np.log(precision) - np.log(2) - np.log(np.pi)\n",
    "    \n",
    "    l_llh = 0.5 * (n_timepoints * constant - precision * sum_res)\n",
    "    \n",
    "    # evaluate log normal-gamma prior\n",
    "    l_prior = log_prior(x)\n",
    "    \n",
    "    # return NEGATIVE log posterior (required for pyPESTO)\n",
    "    return -(l_llh + l_prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the objective function defined, we need to create a pyPESTO problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def standard_sampling():\n",
    "    \"\"\"Creates a pyPESTO problem.\"\"\"\n",
    "    objective = pypesto.Objective(fun=negative_log_posterior)\n",
    "    problem = pypesto.Problem(objective=objective,  # objective function\n",
    "                              lb=[-2, -5, -5, -5, -np.inf, 0],  # lower bounds\n",
    "                              ub=[np.log10(df.Time.max()), 5, 5, 5, np.inf, np.inf],  # upper bounds\n",
    "                              x_names=['t_0', 'k_{TL}*m_0', 'xi', 'delta',\n",
    "                                       'offset', 'precision'],  # parameter names\n",
    "                              x_scales=['log10', 'log10', 'log10', 'log10',\n",
    "                                        'lin', 'lin'])  # parameter scale\n",
    "    return problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "### Prior dependent parameters\n",
    "# center the scaling parameter\n",
    "mu=0\n",
    "# std for scaling parameter --> higher = more constrained / lower = more relaxed\n",
    "alpha=100\n",
    "# center the sigma parameter\n",
    "beta=0.1\n",
    "# std for scaling parameter --> higher = more constrained / lower = more relaxed\n",
    "kappa= 0.01\n",
    "\n",
    "# create the estimation problem\n",
    "problem = standard_sampling()\n",
    "\n",
    "# MCMC chain length\n",
    "n_samples= 1000000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x0 = [np.array([0.2998, 0.9949, -0.1074, -0.6910, 0.2, 1]),\n",
    "      np.array([0.2998, 0.9949, -0.6910, -0.1074, 0.2, 1]),\n",
    "      np.array([0.2998, 0.9949, -0.1074, -0.6910, 0.2, 1]),\n",
    "      np.array([0.2998, 0.9949, -0.6910, -0.1074, 0.2, 1])]\n",
    "\n",
    "cov0 = 1e-4\n",
    "\n",
    "# call the sampler of choice\n",
    "sampler = sample.AdaptiveParallelTemperingSampler(n_chains=4, internal_sampler=\n",
    "                                                  sample.AdaptiveMetropolisSampler(options={'cov0': cov0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [55:43<00:00, 299.06it/s] \n",
      "100%|██████████| 1000000/1000000 [58:45<00:00, 283.68it/s] \n",
      "100%|██████████| 1000000/1000000 [58:08<00:00, 286.66it/s] \n",
      " 70%|███████   | 701073/1000000 [40:57<18:06, 275.21it/s]  "
     ]
    }
   ],
   "source": [
    "# Define number of runs\n",
    "runs = 10\n",
    "start = 10\n",
    "\n",
    "save_results = True # for testing just set to False\n",
    "\n",
    "# Loop over n runs\n",
    "for n in range(runs):\n",
    "    # set initial random seed\n",
    "    np.random.seed(n+start)\n",
    "    # perform MCMC sampling\n",
    "    result = sample.sample(problem, n_samples=n_samples, sampler=sampler, x0=x0)\n",
    "    # calculate effective sample size\n",
    "    sample.effective_sample_size(result=result)\n",
    "\n",
    "    # save the results as a pickle object\n",
    "    if save_results:\n",
    "        results = [result.sample_result, 'mRNA_FP']\n",
    "        with open('Results_mRNA_FP\\\\result_mRNA_FP_'+str(n+start)+'.pickle',\n",
    "                  'wb') as result_file:\n",
    "            pickle.dump(results, result_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize the log posterior trace\n",
    "ax = visualize.sampling_fval_trace(result, size=(12,5), full_trace=True)\n",
    "# Visualize the parameter trace\n",
    "ax = visualize.sampling_parameters_trace(result, use_problem_bounds=False, full_trace=True, size=(12,5))\n",
    "# Visualize the one-dimensional marginals --> Important!\n",
    "ax = visualize.sampling_1d_marginals(result, size=(12,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "result.sample_result.burn_in = 25000\n",
    "# Visualize the log posterior trace\n",
    "ax = visualize.sampling_fval_trace(result, size=(12,5), full_trace=True)\n",
    "# Visualize the parameter trace\n",
    "ax = visualize.sampling_parameters_trace(result, use_problem_bounds=False, full_trace=True, size=(12,5))\n",
    "# Visualize the one-dimensional marginals --> Important!\n",
    "ax = visualize.sampling_1d_marginals(result, size=(12,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (pyPESTO)",
   "language": "python",
   "name": "pycharm-5c126572"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}