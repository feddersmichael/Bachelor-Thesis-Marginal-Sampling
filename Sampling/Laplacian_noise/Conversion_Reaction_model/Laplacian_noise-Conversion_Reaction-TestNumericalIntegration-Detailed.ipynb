{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pypesto\n",
    "import pypesto.petab\n",
    "import pypesto.optimize as optimize\n",
    "import pypesto.sample as sample\n",
    "import pypesto.visualize as visualize\n",
    "\n",
    "import petab\n",
    "import numpy as np\n",
    "from scipy.special import gammaln\n",
    "from scipy.special import gamma\n",
    "import pickle\n",
    "from scipy import integrate\n",
    "from copy import deepcopy\n",
    "\n",
    "datatype = \"original\"\n",
    "\n",
    "# import to petab\n",
    "if datatype == \"original\":\n",
    "    petab_problem = petab.Problem.from_yaml(\n",
    "    \"corrupted_data/SS_conversion_reaction_original.yaml\")\n",
    "elif datatype == \"switch\":\n",
    "    petab_problem = petab.Problem.from_yaml(\n",
    "    \"corrupted_data/SS_conversion_reaction_switch.yaml\")\n",
    "else:\n",
    "    petab_problem = petab.Problem.from_yaml(\n",
    "    \"corrupted_data/SS_conversion_reaction_loss .yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def analytical_b(t, a0, b0, k1, k2):\n",
    "    return (k2 - k2 * np.exp(-(k2 + k1) * t)) / (k2 + k1)\n",
    "\n",
    "def simulate_model(x, tvec):\n",
    "    # assign parameters\n",
    "    k1, k2, _ = x\n",
    "    # define initial conditions\n",
    "    a0 = 1\n",
    "    b0 = 0\n",
    "    # simulate model\n",
    "    simulation = [analytical_b(t, a0, b0, k1, k2)\n",
    "                   for t in tvec]\n",
    "    return simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the model, we need to define the objective function. This time we will do it via an external function that will be used then by pyPESTO instead of using the built-in ones.\n",
    "\n",
    "For numerical reasons we will implement the log likelihood and log prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For calculation-reasons we renumber $y_k$ and $h_k$ so that $\\hat{y}_k - h_k$ are ordered from smallest to biggest, i.e. $y_1 - h_1$ is the smallest number, $y_N - h_N$ the biggest.\n",
    "Then we choose $b_0 = -\\infty, b_i = y_i - h_i (i = 1, \\ldots, N), b_{N+1} = \\infty$. Now we can split the integral in the following parts:\n",
    "\\begin{align*}\n",
    "    \\frac{p(\\sigma)}{2\\sigma} \\left( \\sum_{i = 0}^N \\int_{b_i}^{b_{i+1}}  \\exp \\left\\{- \\frac{\\sum_{k = 1}^N {|c - b_k|}}{\\sigma} \\right\\} p(c)  dc \\right) \n",
    "\\end{align*}\n",
    "with $p(\\sigma) = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def log_prior(offset):\n",
    "    \"\"\" Log prior function.\"\"\"\n",
    "    # assign variables from input x\n",
    "#     scale = x[2]\n",
    "#     offset = x[3]\n",
    "\n",
    "\n",
    "    # exponential prior\n",
    "    exp_prior = np.log(lamda) - lamda * offset\n",
    "\n",
    "    #Gaussian prior\n",
    "    #Gauss_prior = np.log(offset) - (np.log(2) + np.log(np.pi)) / 2 - np.log(tau) - ((offset - mu)/tau)**2 /2\n",
    "\n",
    "    #Laplacian prior\n",
    "    #Lapl_prior = np.log(1) - np.log(2) - np.log(tau) - abs(offset - mu) / tau\n",
    "    \n",
    "    #Amoroso prior\n",
    "    #Amo_prior = - gammaln(c) + np.log(abs(d / b)) + (c * d - 1) * (np.log(scale) - np.log(b)) - (scale / b)**d\n",
    "\n",
    "    return exp_prior\n",
    "\n",
    "\n",
    "def negative_log_posterior(offset,x):\n",
    "    \"\"\" Negative log posterior function.\"\"\"\n",
    "\n",
    "    scale = x[2]\n",
    "#     offset = x[3]\n",
    "\n",
    "    # experimental data\n",
    "    data = np.asarray(petab_problem.measurement_df.measurement)\n",
    "    # time vector\n",
    "    tvec = np.asarray(petab_problem.measurement_df.time)\n",
    "\n",
    "    N = len(tvec)\n",
    "\n",
    "    # simulate model\n",
    "    _simulation = simulate_model(np.exp(x), tvec)\n",
    "    simulation = np.asarray(_simulation)\n",
    "    \n",
    "    # evaluate standard log likelihood\n",
    "    res = data - simulation\n",
    "    b_vector = np.sort(res)\n",
    "    \n",
    "    sum_res = np.sum(abs(offset-b_vector)) / scale\n",
    "\n",
    "    l_llh = - sum_res\n",
    "\n",
    "    # evaluate log normal-gamma prior\n",
    "    l_prior = log_prior(offset)\n",
    "\n",
    "    # return log posterior\n",
    "    return (l_llh + l_prior)\n",
    "\n",
    "def evaluate_posterior_standard(offset,x):\n",
    "    # evaluate log posterior\n",
    "    _P = negative_log_posterior(offset, x)\n",
    "    \n",
    "    # transform to posterior (not log)\n",
    "    return np.exp(_P)\n",
    "\n",
    "def numerical_marginalisation_offset(x):\n",
    "    scale = x[2]\n",
    "    \n",
    "    tvec = np.asarray(petab_problem.measurement_df.time)\n",
    "    N = len(tvec)\n",
    "    \n",
    "    marginal_posterior, _ = integrate.quad(evaluate_posterior_standard, -np.inf, np.inf,args=(x))\n",
    "\n",
    "    log_marginal_posterior = np.log(marginal_posterior)+N*(- np.log(2) -np.log(scale))\n",
    "    \n",
    "    return -log_marginal_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 4.163947227276439\n",
      "Obtained: 4.1639480977344885\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([-1.2741, -0.6160, 0.3684])\n",
    "lamda = 0.01\n",
    "\n",
    "print('Correct: 4.163947227276439')\n",
    "print('Obtained: '+str(numerical_marginalisation_offset(x0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "     \\frac{p(\\sigma)}{2\\sigma} \\left ( \\sum_{i = 0}^N \\exp \\left\\{\\frac{\\bigl( \\sum_{k = 1}^i b_k \\bigr) - \\bigl( \\sum_{k = i + 1}^N b_k \\bigr)}{\\sigma}\\right\\} \\int_{b_i}^{b_{i + 1}} e^{\\frac{c \\cdot (N - 2i)}{\\sigma}} p(c) dc \\right )\n",
    "\\end{align}\n",
    "with $p(\\sigma)=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def log_prior(offset):\n",
    "    \"\"\" Log prior function.\"\"\"\n",
    "\n",
    "    # exponential prior\n",
    "    exp_prior = np.log(lamda) - lamda * offset\n",
    "    return exp_prior\n",
    "\n",
    "\n",
    "def negative_log_posterior(offset,x,N,i):\n",
    "    \"\"\" Negative log posterior function.\"\"\"\n",
    "\n",
    "    scale = x[2]\n",
    "\n",
    "    l_llh = offset*(N-2*i)/scale\n",
    "\n",
    "    # evaluate log normal-gamma prior\n",
    "    l_prior = log_prior(offset)\n",
    "\n",
    "    # return log posterior\n",
    "    return (l_llh + l_prior)\n",
    "\n",
    "def evaluate_posterior_standard(offset,x,N,i):\n",
    "    # evaluate log posterior\n",
    "    _P = negative_log_posterior(offset, x,N,i)\n",
    "    \n",
    "    # transform to posterior (not log)\n",
    "    return np.exp(_P)\n",
    "\n",
    "def numerical_marginalisation_offset(x):\n",
    "    scale = x[2]\n",
    "    \n",
    "    data = np.asarray(petab_problem.measurement_df.measurement)\n",
    "    tvec = np.asarray(petab_problem.measurement_df.time)\n",
    "    N = len(tvec)\n",
    "    \n",
    "    # simulate model\n",
    "    _simulation = simulate_model(np.exp(x), tvec)\n",
    "    simulation = np.asarray(_simulation)\n",
    "    \n",
    "    # evaluate standard log likelihood\n",
    "    res = data - simulation\n",
    "    b_vector = np.sort(res)\n",
    "    \n",
    "    bounds = np.append(np.append(-np.inf, b_vector), np.inf)\n",
    "    \n",
    "    marginal_posterior = 0\n",
    "    for n in range(len(bounds)-1):\n",
    "        _marginal_posterior, _ = integrate.quad(evaluate_posterior_standard, \n",
    "                                                bounds[n], bounds[n+1], \n",
    "                                                args=(x,N,n))\n",
    "        \n",
    "        aux = np.sum(b_vector[:n]) - np.sum(b_vector[n:])\n",
    "\n",
    "        marginal_posterior += _marginal_posterior*np.exp(aux/scale)\n",
    "    \n",
    "    log_marginal_posterior = np.log(marginal_posterior)\n",
    "    log_marginal_posterior += N*(- np.log(2) -np.log(scale))\n",
    "    \n",
    "    return -log_marginal_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 4.163947227276439\n",
      "Obtained: 4.163947167834274\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([-1.2741, -0.6160, 0.3684])\n",
    "lamda = 0.01\n",
    "\n",
    "print('Correct: 4.163947227276439')\n",
    "print('Obtained: '+str(numerical_marginalisation_offset(x0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def negative_log_posterior(offset,x,N,i):\n",
    "    \"\"\" Negative log posterior function.\"\"\"\n",
    "\n",
    "    scale = x[2]\n",
    "\n",
    "    l_llh = offset*((N-2*i)/scale - lamda)\n",
    "\n",
    "    # return log posterior\n",
    "    return l_llh\n",
    "\n",
    "def evaluate_posterior_standard(offset,x,N,i):\n",
    "    # evaluate log posterior\n",
    "    _P = negative_log_posterior(offset, x,N,i)\n",
    "    \n",
    "    # transform to posterior (not log)\n",
    "    return np.exp(_P)\n",
    "\n",
    "def numerical_marginalisation_offset(x):\n",
    "    scale = x[2]\n",
    "    \n",
    "    data = np.asarray(petab_problem.measurement_df.measurement)\n",
    "    tvec = np.asarray(petab_problem.measurement_df.time)\n",
    "    N = len(tvec)\n",
    "    \n",
    "    # simulate model\n",
    "    _simulation = simulate_model(np.exp(x), tvec)\n",
    "    simulation = np.asarray(_simulation)\n",
    "    \n",
    "    # evaluate standard log likelihood\n",
    "    res = data - simulation\n",
    "    b_vector = np.sort(res)\n",
    "    \n",
    "    bounds = np.append(np.append(-np.inf, b_vector), np.inf)\n",
    "    r = np.argmax(bounds >= 0)-1\n",
    "    \n",
    "    marginal_posterior = 0\n",
    "    for n in range(len(bounds)-1):\n",
    "        if n < r:\n",
    "            _marginal_posterior, _ = integrate.quad(evaluate_posterior_standard, \n",
    "                                                    0, bounds[r], \n",
    "                                                    args=(x,N,r))\n",
    "            aux = np.sum(b_vector[:r]) - np.sum(b_vector[r:])\n",
    "        else:\n",
    "            _marginal_posterior, _ = integrate.quad(evaluate_posterior_standard, \n",
    "                                                    bounds[n], bounds[n+1], \n",
    "                                                    args=(x,N,n))\n",
    "        \n",
    "            aux = np.sum(b_vector[:n]) - np.sum(b_vector[n:])\n",
    "\n",
    "        marginal_posterior += _marginal_posterior*np.exp(aux/scale)\n",
    "    \n",
    "    log_marginal_posterior = np.log(marginal_posterior)\n",
    "    log_marginal_posterior += N*(- np.log(2) -np.log(scale))+np.log(lamda) \n",
    "    \n",
    "    return -log_marginal_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 4.163947227276439\n",
      "Obtained: 4.163947167834275\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([-1.2741, -0.6160, 0.3684])\n",
    "lamda = 0.01\n",
    "\n",
    "print('Correct: 4.163947227276439')\n",
    "print('Obtained: '+str(numerical_marginalisation_offset(x0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "& \\frac{\\lambda \\cdot p(\\sigma)}{2\\sigma}  \\Biggl(  e^{l_{r}/\\sigma} \\frac{\\sigma}{N -2r - \\sigma\\lambda} \\cdot \\Biggl( \\exp\\biggl(b_{r + 1} \\cdot \\left(\\frac{N - 2r}{\\sigma} - \\lambda\\right)\\biggr) - 1 \\Biggr) \\label{eq 99} \\\\\n",
    "    &+ \\sum_{i = r + 1}^{N-1} e^{l_i/\\sigma} \\frac{\\sigma}{N - 2i - \\sigma\\lambda} \\Biggl(\\exp\\biggl(b_{i + 1} \\cdot \\left(\\frac{N - 2i}{\\sigma} - \\lambda\\right)\\biggr) - \\exp\\biggl(b_i \\cdot \\left(\\frac{N - 2i}{\\sigma} - \\lambda\\right)\\biggr) \\Biggr) \\nonumber \\nonumber\\\\\n",
    "    &+ e^{l_N/\\sigma} \\frac{\\sigma}{N + \\sigma\\lambda} \\exp\\biggl(b_N \\cdot \\left(\\frac{-N}{\\sigma} - \\lambda\\right)\\biggr) \\Biggr) \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_marginalisation_offset(x):\n",
    "    scale = x[2]\n",
    "    \n",
    "    data = np.asarray(petab_problem.measurement_df.measurement)\n",
    "    tvec = np.asarray(petab_problem.measurement_df.time)\n",
    "    N = len(tvec)\n",
    "    \n",
    "    # simulate model\n",
    "    _simulation = simulate_model(np.exp(x), tvec)\n",
    "    simulation = np.asarray(_simulation)\n",
    "    \n",
    "    # evaluate standard log likelihood\n",
    "    res = data - simulation\n",
    "    b_vector = np.sort(res)\n",
    "    \n",
    "    bounds = np.append(np.append(-np.inf, b_vector), np.inf)\n",
    "    r = np.argmax(bounds >= 0)-1\n",
    "    \n",
    "    marginal_posterior = 0\n",
    "    for n in range(len(bounds)-1):\n",
    "        l_value = np.sum(b_vector[:n]) - np.sum(b_vector[n:])\n",
    "        tmp = l_value/scale\n",
    "        if n < r:\n",
    "            aux1 = scale/(N-2*r-scale*lamda)\n",
    "            aux2 = (np.exp(tmp+bounds[r]*((N-2*r)/scale-lamda))-np.exp(tmp))\n",
    "\n",
    "        elif n == len(bounds)-2:\n",
    "            aux1 = scale/(N+scale*lamda)\n",
    "            aux2 = np.exp(tmp+bounds[n]*(-N/scale-lamda))\n",
    "\n",
    "        else:\n",
    "            aux = (N-2*n)/scale-lamda\n",
    "            aux1 = scale/(N-2*n-scale*lamda)\n",
    "            aux2 = np.exp(tmp+bounds[n+1]*aux)-np.exp(tmp+bounds[n]*aux)\n",
    "        \n",
    "        marginal_posterior += aux1*aux2\n",
    "        \n",
    "    log_marginal_posterior = np.log(marginal_posterior)\n",
    "    log_marginal_posterior += N*(- np.log(2) -np.log(scale))+np.log(lamda) \n",
    "    \n",
    "    return -log_marginal_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaind: -18.142933010755645\n"
     ]
    }
   ],
   "source": [
    "x = np.array([-1.66794275, -0.5614265, 0.01556866])\n",
    "lamda = 0.01\n",
    "\n",
    "print('Obtaind: '+str(numerical_marginalisation_offset(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 4.163947227276439\n",
      "Obtaind: 4.1639471678254525\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([-1.2741, -0.6160, 0.3684])\n",
    "lamda = 0.01\n",
    "\n",
    "print('Correct: 4.163947227276439')\n",
    "print('Obtaind: '+str(numerical_marginalisation_offset(x0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
