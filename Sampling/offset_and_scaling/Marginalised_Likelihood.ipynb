{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pypesto\n",
    "import pypesto.petab\n",
    "import pypesto.optimize as optimize\n",
    "import pypesto.sample as sample\n",
    "import pypesto.visualize as visualize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import petab\n",
    "import numpy as np\n",
    "from scipy.special import gammaln\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# path of the directory\n",
    "d = os.getcwd()\n",
    "# import to petab\n",
    "petab_problem = petab.Problem.from_yaml(\n",
    "    \"Borghans_BiophysChem1997/Borghans_BiophysChem1997.yaml\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytical_b(t, a0, b0, k1, k2):\n",
    "    return (k2 - k2 * np.exp(-(k2 + k1) * t)) / (k2 + k1)\n",
    "\n",
    "def simulate_model(x, tvec):\n",
    "    # assign parameters\n",
    "    k1, k2 = x\n",
    "    # define initial conditions\n",
    "    a0 = 1\n",
    "    b0 = 0.01\n",
    "    # simulate model\n",
    "    simulation = [analytical_b(t, a0, b0, k1, k2)\n",
    "                   for t in tvec]\n",
    "    return simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the model, we need to define the objective function. This time we will do it via an external function that will be used then by pyPESTO instead of using the built-in ones.\n",
    "\n",
    "For numerical reasons we will implement the log likelihood and log prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_log_marginal_posterior(x):\n",
    "    \"\"\"\n",
    "    negative logarithmic marginalized posterior\n",
    "    :param x: x_0 = k1, x_1 = k_2\n",
    "    \"\"\"\n",
    "    \n",
    "    x[:13] = np.power(10, x[:14])\n",
    "    x[-3:] = np.power(10, x[-3:])\n",
    "    \n",
    "    # experimental data\n",
    "    data = np.asarray(petab_problem.measurement_df.measurement)\n",
    "    tvec = np.asarray(petab_problem.measurement_df.time)\n",
    "    \n",
    "    N = len(tvec)    \n",
    "    \n",
    "    _simulation = simulate_model(x, tvec)\n",
    "    simulation = np.asarray(_simulation)\n",
    "    \n",
    "    C_1 = kappa * mu**2 + tau * z**2 + 2 * beta + np.sum(data**2) - (kappa * mu + np.sum(data))**2 /(N + kappa)\n",
    "    \n",
    "    C_2 = ((kappa * mu + np.sum(data)) * (np.sum(simulation)) - (N + kappa) * (tau * z + np.sum(simulation * data)))**2\n",
    "    \n",
    "    C_3 = (N + kappa) * ((N + kappa) * (tau + np.sum(data**2)) - np.sum(simulation)**2)\n",
    "    \n",
    "    C = 0.5 * C_1 - C_2 / (2 * C_3)\n",
    "    \n",
    "    mL_1 = (beta / C)**alpha / (scipy.special.)\n",
    "\n",
    "    \n",
    "    \n",
    "    return -marg_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the objective function defined, we need to create a pyPESTO problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginal_sampling():\n",
    "    \"\"\"Creates a pyPESTO problem.\"\"\"\n",
    "    objective = pypesto.Objective(fun=negative_log_marginal_posterior)\n",
    "    problem = pypesto.Problem(objective=objective,  # objective function\n",
    "                              lb=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0, 0, 0, 0.001, 0.001, 0.001],  # lower bounds\n",
    "                              ub=[100000, 100000, 100000, 100000, 100000, 100000, 100000, 100000, 100000, 100000, 100000, 100000, 100000, 100000, 1, 1, 1, 100000, 100000, 100000],  # upper bounds\n",
    "                              x_names=['K2', 'K_{par}', 'Ka', 'Kd', 'Kf', 'Kp', 'Ky', 'Kz', 'Vd', 'Vm2', 'Vm3', 'Vp', 'beta_{par}', 'epsilon_{par}', 'init_{A, state}', 'init_{Y, state}', 'init_{Z, state}', 'n_{par}', 'v0', 'v1'],  # parameter names\n",
    "                              x_scales=['log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'log10', 'lin', 'lin', 'lin', 'log10', 'log10', 'log10'])  # parameter scale\n",
    "    return problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prior dependent paramters\n",
    "# center the scaling parameter\n",
    "mu=0\n",
    "# std for scaling parameter --> higher = more constrained / lower = more relaxed\n",
    "alpha=100\n",
    "# center the sigma parameter\n",
    "beta=0.1\n",
    "# std for scaling parameter --> higher = more constrained / lower = more relaxed\n",
    "kappa=0.01\n",
    "\n",
    "# create the estimation problem\n",
    "problem = marginal_sampling()\n",
    "\n",
    "# MCMC chain length\n",
    "n_samples= 100000\n",
    "\n",
    "# call the sampler of choice\n",
    "sampler = sample.AdaptiveMetropolisSampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform the actual sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of runs\n",
    "runs = 1\n",
    "\n",
    "save_results = True # for testing just set to False\n",
    "\n",
    "# Loop over n runs\n",
    "for n in range(runs):\n",
    "    # set initial random seed\n",
    "    np.random.seed(n)\n",
    "    # perform MCMC sampling\n",
    "    result = sample.sample(problem, n_samples=n_samples, sampler=sampler,\n",
    "                           x0=np.array([-1.2741, -0.6160]))\n",
    "    # calculate effective sample size\n",
    "    sample.effective_sample_size(result=result)\n",
    "\n",
    "    # save the results as a pickle object\n",
    "    if save_results:\n",
    "        results = [result.sample_result, 'CR_MP']\n",
    "        with open('Results/result_CR_MP_'+str(n)+'.pickle', \n",
    "                  'wb') as result_file:\n",
    "            pickle.dump(results, result_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some built-in visualization functions that one can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the parameter trace\n",
    "ax = visualize.sampling.sampling_parameters_trace(result, use_problem_bounds=False, full_trace=True, size=(12,5))\n",
    "# Visualize the one-dimensional marginals --> Important!\n",
    "ax = visualize.sampling_1d_marginals(result, size=(12,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our marginal sampling results we now want to sample $c$ and $\\lambda$ based on the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "    \\lambda \\propto \\operatorname{Gamma}(\\alpha' = \\alpha + N/2, \\beta' = C). \\label{eq precision from data}\n",
    "\\end{align}\n",
    "for\n",
    "\\begin{align*}\n",
    "    C \\equiv  \\frac{1}{2}\\Biggl( \\Biggl( \\sum_{k = 1}^N (\\overline{y_k} - h_k)^2 \\Biggr) + \\kappa \\mu^2 + 2\\beta \\Biggr) -  \\frac{1}{2(N + \\kappa)} \\Biggl(\\Biggl(\\sum_{k = 1}^N \\overline{y_k} - h_k\\Biggr)+ \\kappa \\mu \\Biggr)^2\n",
    "\\end{align*}\n",
    "and\n",
    "\\begin{align*}\n",
    "    c \\propto \\mathcal{N} \\left(\\mu' = \\frac{\\left(\\sum_{k = 1}^N \\overline{y_k}-h_k \\right) + \\kappa \\mu }{N + \\kappa}, \\hat{\\lambda} = \\lambda (N + \\kappa) \\right)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec = np.asarray(petab_problem.measurement_df.time)\n",
    "N = len(tvec)\n",
    "data_model = np.asarray(petab_problem.measurement_df.measurement)\n",
    "fig, axs = plt.subplots(nrows=2, figsize=(12, 5))\n",
    "\n",
    "def Constant(x):\n",
    "    _simulation = simulate_model(np.exp(x), tvec)\n",
    "    simulation = np.asarray(_simulation)\n",
    "\n",
    "    res = data_model - simulation\n",
    "    \n",
    "    summand_1 = (np.sum(res**2) + kappa * mu **2 + 2 * beta)/2\n",
    "    summand_2 = (1 / (2 * (N + kappa))) * (np.sum(res) + kappa * mu)**2\n",
    "    \n",
    "    return summand_1 - summand_2\n",
    "    \n",
    "\n",
    "Generator = np.random.default_rng()\n",
    "results = pypesto.Result(marginal_sampling())\n",
    "\n",
    "\n",
    "with open(d + '/Results/result_CR_MP_0.pickle', 'rb') as infile:\n",
    "    results.sample_result = pickle.load(infile)[0]\n",
    "                 \n",
    "precision_list = np.zeros(np.shape(results.sample_result.trace_x)[1]) \n",
    "\n",
    "for index, data in enumerate(results.sample_result.trace_x[0, :, :]):\n",
    "    shape = alpha + N/2\n",
    "    scale = 1/Constant(data)\n",
    "    precision_list[index] = Generator.gamma(shape, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axs[0] = sns.distplot(precision_list, rug=True, axlabel='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_(x):\n",
    "    _simulation = simulate_model(np.exp(x), tvec)\n",
    "    simulation = np.asarray(_simulation)\n",
    "\n",
    "    res = data_model - simulation\n",
    "    result_ = np.sum(res) + kappa * mu\n",
    "    return result_/(N + kappa)\n",
    "    \n",
    "offset_list = np.zeros(np.shape(results.sample_result.trace_x)[1]) \n",
    "\n",
    "for index, data in enumerate(results.sample_result.trace_x[0, :, :]):\n",
    "    new_mu = mu_(data)\n",
    "    new_sigmasquare = 1/((N + kappa)*precision_list[index])\n",
    "    offset_list[index] = Generator.normal(new_mu, new_sigmasquare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axs[1] = sns.distplot(offset_list, rug=True, axlabel='offset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "plt.savefig(fname=d + '\\\\offset_and_precision.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}