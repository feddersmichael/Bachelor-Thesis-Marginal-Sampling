{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pypesto\n",
    "import pypesto.petab\n",
    "import pypesto.sample as sample\n",
    "import pypesto.visualize as visualize\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import petab\n",
    "import numpy as np\n",
    "from scipy import integrate\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = \"original\"\n",
    "\n",
    "# Load experimental data\n",
    "if datatype == \"original\":\n",
    "    df=pd.read_csv('data/data.csv', sep='\\t')\n",
    "elif datatype == \"switch\":\n",
    "    df=pd.read_csv('data/data_switch.csv', sep='\\t')\n",
    "else:\n",
    "    df=pd.read_csv('data/data_loss.csv', sep='\\t')\n",
    "\n",
    "add_scaling_to_data = True\n",
    "scaling_value = 2\n",
    "\n",
    "if add_scaling_to_data:\n",
    "    df.Measurement=df.Measurement*scaling_value\n",
    "    \n",
    "data = np.asarray(df.Measurement)\n",
    "\n",
    "tvec = np.asarray(df.Time)\n",
    "    \n",
    "N = len(tvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#now we interpret kTL_m0 as the scaling factor, therefore we have to take it out of the formula\n",
    "\n",
    "\n",
    "def analytical_x2(t, t0, xi, delta):\n",
    "    X = [np.exp(-delta*(t-t0)) * (t>t0),\n",
    "         (np.exp(-xi*(t-t0)) - np.exp(-delta*(t-t0))) / (delta-xi) * (t>t0)]\n",
    "    return X[1]\n",
    "\n",
    "def simulate_model(x, tvec):\n",
    "    # assign parameters\n",
    "    t0, xi, delta, _ = x\n",
    "    # simulate model\n",
    "    simulation = np.asarray([analytical_x2(t, t0, xi, delta)\n",
    "                             for t in tvec])\n",
    "    return simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the model, we need to define the objective function. This time we will do it via an external function that will be used then by pyPESTO instead of using the built-in ones.\n",
    "\n",
    "For numerical reasons we will implement the log likelihood and log prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def negative_log_marginalised_posterior(x):\n",
    "    \"\"\" Negative log posterior function.\"\"\"\n",
    "\n",
    "    shape = x[3]\n",
    "\n",
    "    # simulate model\n",
    "    simulation = simulate_model(np.power(10, x), tvec)\n",
    "    \n",
    "    \n",
    "    #we need now to sort the b-vector by size, remove the values for simulation = 0 and then apply\n",
    "    #this order to the data and simulation as well\n",
    "    \n",
    "    #we devide by the accordng values and set -1 where simulation would be 0\n",
    "    b_vector_us = np.divide(data, simulation, out = -np.ones(N), where=simulation!=0)\n",
    "    #now these values are at the start and the rest is sorted\n",
    "    b_vector_l = np.sort(b_vector_us)\n",
    "    #we safe the order\n",
    "    sort_order = np.searchsorted(b_vector_l, b_vector_us)\n",
    "    #and determine how many simulation avlues are 0\n",
    "    zero_amnt = np.argmax(b_vector_l > -1)\n",
    "    #they get removed from the b vector\n",
    "    b_vector = b_vector_l[zero_amnt:]\n",
    "    \n",
    "    #N' is the amount of integral breaks\n",
    "    N_prime = N - zero_amnt\n",
    "    #we need only N values in the end but add soem spaces for convenience later\n",
    "    data_sorted = np.ones(N + zero_amnt) - 2\n",
    "    simulation_sorted = np.ones(N + zero_amnt) - 2\n",
    "    \n",
    "    for i in range(N):\n",
    "        # in case that several values in b_vector have the same value\n",
    "        j = 0 \n",
    "        while simulation_sorted[sort_order[i] + j] != -1:\n",
    "            j += 1\n",
    "            \n",
    "        simulation_sorted[sort_order[i] + j] = simulation[i]\n",
    "        data_sorted[sort_order[i] + j] = data[i]\n",
    "        \n",
    "        \n",
    "    for i in range(zero_amnt):\n",
    "        data_sorted[N + i] = data_sorted[i]\n",
    "        simulation_sorted[N + i] = simulation_sorted[i]\n",
    "        \n",
    "    data_sorted = data_sorted[zero_amnt:]\n",
    "    simulation_sorted = simulation_sorted[zero_amnt:]\n",
    "    \n",
    "    bounds = np.append(np.append(0, b_vector), np.inf)\n",
    "    \n",
    "    d_vector = -np.sum(data_sorted)\n",
    "    # we can just sum up the whole array because values >= N' are 0 by construction\n",
    "    q_vector = np.sum(simulation_sorted)\n",
    "    \n",
    "    l_llh = 0\n",
    "    const = lamda*shape\n",
    "    check = q_vector - const\n",
    "    \n",
    "    for i in range(N_prime):\n",
    "        \n",
    "        if check != 0:\n",
    "            aux1 = (shape / check)\n",
    "            aux2 = np.exp((d_vector + bounds[i + 1] * check) / shape) \\\n",
    "                -  np.exp((d_vector + bounds[i] * check) / shape)\n",
    "        else:\n",
    "            aux1 = np.exp(d_vector / shape)\n",
    "            aux2 = bounds[i + 1] - bounds[i]\n",
    "        \n",
    "        l_llh += aux1 * aux2\n",
    "        d_vector = d_vector + 2*data_sorted[i]\n",
    "        q_vector = q_vector - 2*simulation_sorted[i]\n",
    "        check = q_vector - const\n",
    "        \n",
    "    l_llh = l_llh - (shape / check) * np.exp((d_vector + bounds[N_prime] * check) / shape)\n",
    "    \n",
    "    # return NEGATIVE log posterior (required for pyPESTO)\n",
    "    return -(np.log(lamda) - N*(np.log(2) + np.log(shape)) + np.log(l_llh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior(scale, shape, simulation):\n",
    "    \"\"\" Negative log posterior function.\"\"\"\n",
    "\n",
    "    diff = -abs(data - scale*simulation) / shape\n",
    "    factor1 = np.prod(np.exp(diff))\n",
    "    factor2 = 1 / ((2 * shape)**N)\n",
    "\n",
    "    llh = factor1 * factor2\n",
    "    prior = lamda * np.exp(-lamda * scale)\n",
    "\n",
    "    return llh * prior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_log_post(shape, simulation):\n",
    "    numerical_value, _ = integrate.quad(posterior, 0, np.inf, args=(shape, simulation))\n",
    "\n",
    "    return np.log(numerical_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the objective function defined, we need to create a pyPESTO problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def standard_sampling():\n",
    "    \"\"\"Creates a pyPESTO problem.\"\"\"\n",
    "    objective = pypesto.Objective(fun=negative_log_marginalised_posterior)\n",
    "    problem = pypesto.Problem(objective=objective,  # objective function\n",
    "                              lb=[-2, -5, -5, np.exp(-5)],  # lower bounds\n",
    "                              ub=[np.log10(df.Time.max()), 5, 5, np.exp(5)],  # upper bounds\n",
    "                              x_names=['t_0', 'xi', 'delta',\n",
    "                                       'shape'],  # parameter names\n",
    "                              x_scales=['log10', 'log10', 'log10',\n",
    "                                        'lin'])  # parameter scale\n",
    "    return problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Prior dependent paramters\n",
    "\n",
    "lamda = 0.01\n",
    "\n",
    "# create the estimation problem\n",
    "problem = standard_sampling()\n",
    "\n",
    "# MCMC chain length\n",
    "n_samples= 1000000\n",
    "\n",
    "# call the sampler of choice\n",
    "sampler = sample.AdaptiveMetropolisSampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = [np.array([0.2998, -0.1074, -0.6910, 0.2]),\n",
    "      np.array([0.2998, -0.1074, -0.6910, 0.2]),\n",
    "      np.array([0.2998, -0.1074, -0.6910, 0.2]),\n",
    "      np.array([0.2998, -0.1074, -0.6910, 0.2]),\n",
    "      np.array([0.2998, -0.1074, -0.6910, 0.2]),\n",
    "      np.array([0.2998, -0.1074, -0.6910, 0.2]),\n",
    "      np.array([0.2998, -0.1074, -0.6910, 0.2]),\n",
    "      np.array([0.2998, -0.1074, -0.6910, 0.2]),\n",
    "      np.array([0.2998, -0.1074, -0.6910, 0.2]),\n",
    "      np.array([0.2998, -0.1074, -0.6910, 0.2])]\n",
    "\n",
    "cov0 = 1e-4\n",
    "\n",
    "# call the sampler of choice\n",
    "sampler = sample.AdaptiveParallelTemperingSampler(n_chains=10, internal_sampler=\n",
    "                                                  sample.AdaptiveMetropolisSampler(options={'cov0': cov0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7402/1000000 [01:17<2:53:55, 95.12it/s] \n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mLinAlgError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/z3/5_1pjw5j79x2_qs3v_2dhl1c0000gn/T/ipykernel_46848/103722752.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mseed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0;31m# perform MCMC sampling\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m     \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msample\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msample\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mproblem\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_samples\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mn_samples\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msampler\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msampler\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx0\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mx0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     11\u001B[0m     \u001B[0;31m# calculate effective sample size\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[0msample\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meffective_sample_size\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/Bachelor-Thesis-Marginal-Sampling/venv/lib/python3.8/site-packages/pypesto/sample/sample.py\u001B[0m in \u001B[0;36msample\u001B[0;34m(problem, n_samples, sampler, x0, result)\u001B[0m\n\u001B[1;32m     66\u001B[0m     \u001B[0;31m# perform the sampling and track time\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m     \u001B[0mt_start\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mprocess_time\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 68\u001B[0;31m     \u001B[0msampler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msample\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_samples\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mn_samples\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     69\u001B[0m     \u001B[0mt_elapsed\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mprocess_time\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mt_start\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m     \u001B[0mlogger\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minfo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Elapsed time: \"\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt_elapsed\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/Bachelor-Thesis-Marginal-Sampling/venv/lib/python3.8/site-packages/pypesto/sample/parallel_tempering.py\u001B[0m in \u001B[0;36msample\u001B[0;34m(self, n_samples, beta)\u001B[0m\n\u001B[1;32m     68\u001B[0m             \u001B[0;31m# sample\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0msampler\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbeta\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msamplers\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbetas\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 70\u001B[0;31m                 \u001B[0msampler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msample\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_samples\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbeta\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbeta\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     71\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     72\u001B[0m             \u001B[0;31m# swap samples\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/Bachelor-Thesis-Marginal-Sampling/venv/lib/python3.8/site-packages/pypesto/sample/metropolis.py\u001B[0m in \u001B[0;36msample\u001B[0;34m(self, n_samples, beta)\u001B[0m\n\u001B[1;32m     54\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0m_\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_samples\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdisable\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mnot\u001B[0m \u001B[0mshow_progress\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     55\u001B[0m             \u001B[0;31m# perform step\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 56\u001B[0;31m             x, lpost, lprior = self._perform_step(\n\u001B[0m\u001B[1;32m     57\u001B[0m                 x=x, lpost=lpost, lprior=lprior, beta=beta)\n\u001B[1;32m     58\u001B[0m             \u001B[0;31m# record step\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/Bachelor-Thesis-Marginal-Sampling/venv/lib/python3.8/site-packages/pypesto/sample/metropolis.py\u001B[0m in \u001B[0;36m_perform_step\u001B[0;34m(self, x, lpost, lprior, beta)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    114\u001B[0m         \u001B[0;31m# update proposal\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 115\u001B[0;31m         self._update_proposal(x, lpost,\n\u001B[0m\u001B[1;32m    116\u001B[0m                               log_p_acc, len(self.trace_neglogpost)+1)\n\u001B[1;32m    117\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/Bachelor-Thesis-Marginal-Sampling/venv/lib/python3.8/site-packages/pypesto/sample/adaptive_metropolis.py\u001B[0m in \u001B[0;36m_update_proposal\u001B[0;34m(self, x, lpost, log_p_acc, n_sample_cur)\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     86\u001B[0m         \u001B[0;31m# regularize proposal covariance\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 87\u001B[0;31m         self._cov = regularize_covariance(\n\u001B[0m\u001B[1;32m     88\u001B[0m             cov=self._cov, reg_factor=reg_factor)\n\u001B[1;32m     89\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/Bachelor-Thesis-Marginal-Sampling/venv/lib/python3.8/site-packages/pypesto/sample/adaptive_metropolis.py\u001B[0m in \u001B[0;36mregularize_covariance\u001B[0;34m(cov, reg_factor)\u001B[0m\n\u001B[1;32m    150\u001B[0m         \u001B[0mRegularized\u001B[0m \u001B[0mestimate\u001B[0m \u001B[0mof\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mcovariance\u001B[0m \u001B[0mmatrix\u001B[0m \u001B[0mof\u001B[0m \u001B[0mthe\u001B[0m \u001B[0msample\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    151\u001B[0m     \"\"\"\n\u001B[0;32m--> 152\u001B[0;31m     \u001B[0meig\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinalg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meigvals\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcov\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    153\u001B[0m     \u001B[0meig_min\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0meig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    154\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0meig_min\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<__array_function__ internals>\u001B[0m in \u001B[0;36meigvals\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/Bachelor-Thesis-Marginal-Sampling/venv/lib/python3.8/site-packages/numpy/linalg/linalg.py\u001B[0m in \u001B[0;36meigvals\u001B[0;34m(a)\u001B[0m\n\u001B[1;32m   1060\u001B[0m     \u001B[0m_assert_stacked_2d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1061\u001B[0m     \u001B[0m_assert_stacked_square\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1062\u001B[0;31m     \u001B[0m_assert_finite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1063\u001B[0m     \u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult_t\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_commonType\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1064\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/Bachelor-Thesis-Marginal-Sampling/venv/lib/python3.8/site-packages/numpy/linalg/linalg.py\u001B[0m in \u001B[0;36m_assert_finite\u001B[0;34m(*arrays)\u001B[0m\n\u001B[1;32m    206\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0ma\u001B[0m \u001B[0;32min\u001B[0m \u001B[0marrays\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    207\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misfinite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 208\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mLinAlgError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Array must not contain infs or NaNs\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    209\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    210\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_is_empty_2d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mLinAlgError\u001B[0m: Array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "# Define number of runs\n",
    "runs = 1\n",
    "save_results = False # for testing just set to False\n",
    "\n",
    "# Loop over n runs\n",
    "for n in range(runs):\n",
    "    # set initial random seed\n",
    "    np.random.seed(n)\n",
    "    # perform MCMC sampling\n",
    "    result = sample.sample(problem, n_samples=n_samples, sampler=sampler, x0=x0)\n",
    "    # calculate effective sample size\n",
    "    sample.effective_sample_size(result=result)\n",
    "\n",
    "    # save the results as a pickle object\n",
    "    if save_results:\n",
    "        results = result.sample_result\n",
    "        with open('Results/Full_parameter/' + str(n) + '.pickle','wb') as result_file:\n",
    "            pickle.dump(results, result_file, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some built-in visualization functions that one can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(result.sample_result.effective_sample_size)\n",
    "print(result.sample_result.effective_sample_size/result.sample_result.time)\n",
    "# Visualize the parameter trace\n",
    "ax = visualize.sampling.sampling_parameters_trace(result, use_problem_bounds=False, full_trace=True, size=(12,5))\n",
    "# Visualize the one-dimensional marginals --> Important!\n",
    "ax = visualize.sampling_1d_marginals(result, size=(12,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scale $s$ is distributed proportional to the density function\n",
    "\\begin{align*}\n",
    "    \\sum_{i = 0}^{N'} \\mathbf{1}_{[b_i, b_{i + 1}))}(s) \\exp \\left\\{s \\cdot \\frac{q_i -\\lambda \\sigma}{\\sigma}\\right\\}\n",
    "\\end{align*}\n",
    "\n",
    "The corresponding intgral values are\n",
    "\\begin{align*}\n",
    "    I_i &= \\exp \\left\\{\\frac{d_i}{\\sigma} \\right\\}  c_i \\\\\n",
    "    \\text{with} \\ c_{i = 1, \\ldots, N'-1} &=\n",
    "    \\begin{cases}\n",
    "        \\frac{\\sigma}{q_i -\\lambda \\sigma} \\left( \\exp \\left\\{b_{i + 1} \\cdot \\frac{q_i -\\lambda \\sigma}{\\sigma} \\right\\} - \\exp \\left\\{b_i \\cdot \\frac{q_i -\\lambda \\sigma}{\\sigma} \\right\\}\\right) &\\text{if $q_i \\neq \\lambda \\sigma$} \\\\\n",
    "        b_{i + 1} - b_i &\\text{if $q_i = \\lambda \\sigma$}\n",
    "    \\end{cases} \\\\\n",
    "    \\text{and because $\\frac{q_{N'} - \\lambda \\sigma}{\\sigma} < 0$} \\quad c_{N'} &= \\frac{\\sigma}{\\lambda \\sigma - q_{N'}} \\exp \\left\\{b_{N'} \\cdot \\frac{q_{N'} -\\lambda \\sigma}{\\sigma} \\right\\}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scale(simulation, shape):    \n",
    "    \n",
    "    b_vector_us = np.divide(data, simulation, out = -np.ones(N), where=simulation!=0)\n",
    "    b_vector_l = np.sort(b_vector_us)\n",
    "    sort_order = np.searchsorted(b_vector_l, b_vector_us)\n",
    "    zero_amnt = np.argmax(b_vector_l > -1)\n",
    "    b_vector = b_vector_l[zero_amnt:]\n",
    "    bounds = np.append(np.append(0, b_vector), np.inf)\n",
    "    \n",
    "    \n",
    "    N_prime = N - zero_amnt\n",
    "    data_sorted = np.ones(N + zero_amnt) -2\n",
    "    simulation_sorted = np.ones(N + zero_amnt) -2\n",
    "    \n",
    "    for i in range(N):\n",
    "        j = 0 # in case that several values in b_vector have the same value\n",
    "        while simulation_sorted[sort_order[i] + j] != -1:\n",
    "            j += 1\n",
    "            \n",
    "        simulation_sorted[sort_order[i] + j] = simulation[i]\n",
    "        data_sorted[sort_order[i] + j] = data[i]\n",
    "        \n",
    "        \n",
    "    for i in range(zero_amnt):\n",
    "        data_sorted[N + i] = data_sorted[i]\n",
    "        simulation_sorted[N + i] = simulation_sorted[i]\n",
    "        \n",
    "    data_sorted = data_sorted[zero_amnt:]\n",
    "    simulation_sorted = simulation_sorted[zero_amnt:]\n",
    "    \n",
    "    \n",
    "    \n",
    "    d_vector = -np.sum(data_sorted)\n",
    "    q_vector = np.sum(simulation_sorted)\n",
    "    \n",
    "    probability_mass = np.zeros(N_prime + 1)\n",
    "    \n",
    "    const = lamda*shape\n",
    "    check = q_vector - const\n",
    "    \n",
    "    #initial case i = 0\n",
    "    if check == 0:\n",
    "        aux1 = np.exp(d_vector / shape)\n",
    "        aux2 = bounds[1]\n",
    "        probability_mass[0] = aux1 * aux2\n",
    "            \n",
    "    else:\n",
    "        aux1 = np.exp((bounds[1] * check + d_vector)/ shape)\n",
    "        aux2 = np.exp(d_vector / shape)\n",
    "        aux3 = shape / check\n",
    "        probability_mass[0] = aux3*(aux1 - aux2)\n",
    "    \n",
    "    d_vector = d_vector + 2*data_sorted[0]\n",
    "    q_vector = q_vector - 2*simulation_sorted[0]\n",
    "    check = q_vector - const\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(1, N_prime):\n",
    "        \n",
    "        if check != 0:\n",
    "            aux1 = (shape / check)\n",
    "            aux2 = np.exp((d_vector + bounds[i + 1] * check) / shape) \\\n",
    "                -  np.exp((d_vector + bounds[i] * check) / shape)\n",
    "        else:\n",
    "            aux1 = np.exp(d_vector / shape)\n",
    "            aux2 = bounds[i + 1] - bounds[i]\n",
    "        \n",
    "        probability_mass[i] += aux1 * aux2\n",
    "        d_vector = d_vector + 2*data_sorted[i]\n",
    "        q_vector = q_vector - 2*simulation_sorted[i]\n",
    "        check = q_vector - const\n",
    "        \n",
    "    normalisation_constant = probability_mass[N_prime-1] - (shape / check) \\\n",
    "            * np.exp((d_vector + bounds[N_prime] * check) / shape)  \n",
    "    \n",
    "    probability_mass = probability_mass / normalisation_constant\n",
    "    probability_mass[N_prime] = 1\n",
    "    \n",
    "    s = Generator.uniform(size = 2)\n",
    "    i = np.argmax(probability_mass > s[0])\n",
    "    q_vector = np.sum(simulation_sorted[i + 1:]) - np.sum(simulation_sorted[:i + 1])\n",
    "    factor = (q_vector - lamda * shape) / shape\n",
    "    \n",
    "    if factor == 0:\n",
    "        scale = s[1] * (bounds[i + 1] - bounds[i])\n",
    "    else:\n",
    "        lb = bounds[i]\n",
    "\n",
    "        if i == N_prime:\n",
    "            scale = np.log(1 - s[1])/ factor + lb\n",
    "        else:\n",
    "            ub = bounds[i + 1]\n",
    "            compensate = factor * ub\n",
    "            scale = (compensate + np.log(np.exp(factor*lb - compensate) \\\n",
    "                   + s[1] *(np.exp(factor*ub - compensate) - np.exp(factor*lb - compensate)))) / factor\n",
    "            \n",
    "    return scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Generator = np.random.default_rng()\n",
    "\n",
    "scale_samples = np.zeros([np.shape(\n",
    "    result.sample_result.trace_x[0, result.sample_result.burn_in:, 0])[0], 1])\n",
    "\n",
    "for index, parameter_sample in enumerate(result.sample_result.trace_x[0, result.sample_result.burn_in:, :]):\n",
    "    shape = parameter_sample[-1]\n",
    "    simulation = simulate_model(np.power(10, parameter_sample), tvec)\n",
    "    \n",
    "    scale_samples[index, :] = get_scale(simulation, shape)\n",
    "    \n",
    "if save_results:\n",
    "    results = [result.sample_result, scale_samples]\n",
    "    with open('Results/Offset_marginalized/' + str(n) + '.pickle','wb') as result_file:\n",
    "        pickle.dump(results, result_file, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = sns.kdeplot(scale_samples[:,0], shade=True, color='C0')\n",
    "plt.xlabel('scale')\n",
    "plt.ylabel('kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_MAP = True\n",
    "\n",
    "if plot_MAP:\n",
    "    MAP_index = np.argmax(-result.sample_result.trace_neglogpost[0,result.sample_result.burn_in:])\n",
    "    MAP = result.sample_result.trace_x[0,result.sample_result.burn_in+MAP_index,:]\n",
    "    print(MAP)\n",
    "\n",
    "    tvec_for_simulation = np.linspace(tvec[0],tvec[-1],100)\n",
    "    \n",
    "    shape_MAP = MAP[-1]\n",
    "    \n",
    "    #changing scale to resampled values\n",
    "    \n",
    "    simulation = simulate_model(np.power(10, MAP), tvec)\n",
    "\n",
    "    scale = get_scale(simulation, shape_MAP)\n",
    "    print(scale)\n",
    "\n",
    "    # simulate model\n",
    "    _simulation = np.asarray(simulate_model(np.power(10, MAP), tvec_for_simulation))\n",
    "    simulation_for_plotting = np.asarray(scale * _simulation)\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(tvec,data,'or',label='Corrupted data')\n",
    "    plt.plot(tvec_for_simulation,simulation_for_plotting,'k',label='MAP simulation')\n",
    "    plt.xlabel('Time [a.u.]')\n",
    "    plt.ylabel('Signal [a.u.]')\n",
    "    #plt.ylim([0,2])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}